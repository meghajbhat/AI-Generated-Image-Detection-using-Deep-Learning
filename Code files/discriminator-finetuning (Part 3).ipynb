{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726},{"sourceId":8497982,"sourceType":"datasetVersion","datasetId":5070657},{"sourceId":11482464,"sourceType":"datasetVersion","datasetId":7196652},{"sourceId":11486045,"sourceType":"datasetVersion","datasetId":7199217}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T13:57:15.840079Z","iopub.execute_input":"2025-04-19T13:57:15.840295Z","iopub.status.idle":"2025-04-19T13:57:17.159855Z","shell.execute_reply.started":"2025-04-19T13:57:15.840272Z","shell.execute_reply":"2025-04-19T13:57:17.159082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport os\n\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.root_dir = root_dir\n        self.image_paths = [os.path.join(root_dir, fname) \n                            for fname in os.listdir(root_dir) \n                            if fname.endswith(('.png', '.jpg', '.jpeg'))]\n        self.transform = transform\n        self.label = label\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:37:20.975831Z","iopub.execute_input":"2025-04-20T17:37:20.976443Z","iopub.status.idle":"2025-04-20T17:37:20.982355Z","shell.execute_reply.started":"2025-04-20T17:37:20.976418Z","shell.execute_reply":"2025-04-20T17:37:20.981632Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, ConcatDataset, Dataset\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Parameters\nbatch_size = 128\nimage_size = 32\nnc = 3\nndf = 64\nnum_epochs = 10\nlr = 0.0001  # Lower learning rate for fine-tuning\nbeta1 = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Custom dataset class for flat directory structure\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.root_dir = root_dir\n        self.image_paths = [\n            os.path.join(root_dir, fname)\n            for fname in os.listdir(root_dir)\n            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n        ]\n        self.transform = transform\n        self.label = label\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.label\n\n# Image transforms\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Dataset paths\nreal_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL\"\nfake_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE\"\n\n# Datasets\nreal_dataset = FlatImageFolder(real_dir, label=1, transform=transform)\nfake_dataset = FlatImageFolder(fake_dir, label=0, transform=transform)\n\n# Combine and create DataLoader\ntrain_dataset = ConcatDataset([real_dataset, fake_dataset])\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\n# Discriminator model architecture (kept the same to match the pre-trained model)\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.main(x).view(-1)\n\n# Instantiate model\nnetD = Discriminator().to(device)\n\n# Load the pre-trained discriminator\npretrained_path = \"/kaggle/input/discriminatortdl/dcgan_discriminator.pth\"\nnetD.load_state_dict(torch.load(pretrained_path, map_location=device))\nprint(f\"Loaded pre-trained discriminator from {pretrained_path}\")\n\n# Loss function and optimizer for fine-tuning\ncriterion = nn.BCELoss()\noptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n\n# Fine-tuning loop\ndef finetune_discriminator():\n    D_losses = []\n    D_accuracies = []\n    print(\"Fine-tuning Discriminator on CIFAKE dataset...\")\n    \n    for epoch in range(num_epochs):\n        epoch_loss = 0.0\n        correct_predictions = 0\n        total_samples = 0\n        \n        for i, (data, labels) in enumerate(train_loader):\n            # Move data to device\n            data = data.to(device)\n            labels = labels.float().to(device)\n            \n            # Forward pass\n            netD.zero_grad()\n            output = netD(data)\n            \n            # Calculate loss\n            loss = criterion(output, labels)\n            \n            # Backward pass and optimization\n            loss.backward()\n            optimizerD.step()\n            \n            # Record loss\n            D_losses.append(loss.item())\n            epoch_loss += loss.item()\n            \n            # Calculate accuracy\n            predicted = (output >= 0.5).float()\n            correct_predictions += (predicted == labels).sum().item()\n            total_samples += labels.size(0)\n            \n            # Print progress\n            if i % 50 == 0:\n                print(f\"[{epoch+1}/{num_epochs}][{i}/{len(train_loader)}] Loss_D: {loss.item():.4f}\")\n        \n        # Calculate epoch statistics\n        epoch_accuracy = correct_predictions / total_samples\n        D_accuracies.append(epoch_accuracy)\n        avg_epoch_loss = epoch_loss / len(train_loader)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs} - Avg Loss: {avg_epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n    \n    return D_losses, D_accuracies\n\n# Run fine-tuning\nD_losses, D_accuracies = finetune_discriminator()\n\n# Plot loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(D_losses)\nplt.title(\"Discriminator Fine-tuning Loss\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.grid(True)\n\n# Plot accuracy per epoch\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs + 1), D_accuracies, marker='o')\nplt.title(\"Discriminator Accuracy per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\nplt.tight_layout()\n\nplt.savefig(\"discriminator_finetuning_cifake.png\")\nplt.show()\n\n# Save the fine-tuned discriminator\ntorch.save(netD.state_dict(), \"finetuned_discriminator_cifake.pth\")\n\n# Evaluate on test set if available\ntry:\n    test_real_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL\"\n    test_fake_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE\"\n    \n    test_real_dataset = FlatImageFolder(test_real_dir, label=1, transform=transform)\n    test_fake_dataset = FlatImageFolder(test_fake_dir, label=0, transform=transform)\n    test_dataset = ConcatDataset([test_real_dataset, test_fake_dataset])\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    \n    netD.eval()\n    test_correct = 0\n    test_total = 0\n    \n    with torch.no_grad():\n        for data, labels in test_loader:\n            data = data.to(device)\n            labels = labels.to(device)\n            outputs = netD(data)\n            predicted = (outputs >= 0.5).float()\n            test_correct += (predicted == labels).sum().item()\n            test_total += labels.size(0)\n    \n    test_accuracy = test_correct / test_total\n    print(f\"Test accuracy: {test_accuracy:.4f}\")\n    \nexcept Exception as e:\n    print(f\"Test set evaluation failed: {e}\")\n    print(\"Skipping test set evaluation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:35:38.889515Z","iopub.execute_input":"2025-04-20T17:35:38.889786Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Loaded pre-trained discriminator from /kaggle/input/discriminatortdl/dcgan_discriminator.pth\nFine-tuning Discriminator on CIFAKE dataset...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1591142696.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  netD.load_state_dict(torch.load(pretrained_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"[1/10][0/782] Loss_D: 0.6565\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nimport numpy as np\n\n# Set random seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\n# Parameters\nbatch_size = 64\nimage_size = 32\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnum_epochs = 10  # Reduced epochs for fine-tuning\nlr_d = 0.00005  # Lower learning rate for fine-tuning\nbeta1 = 0.5\nbeta2 = 0.999\n\n# Custom dataset class for flat directory structure\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.root_dir = root_dir\n        self.image_paths = [\n            os.path.join(root_dir, fname)\n            for fname in os.listdir(root_dir)\n            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n        ]\n        self.transform = transform\n        self.label = label\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.label\n\n# Image transforms\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n])\n\n# Dataset paths\nreal_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL\"\nfake_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE\"\n\n# Datasets\nreal_dataset = FlatImageFolder(real_dir, label=1, transform=transform)\nfake_dataset = FlatImageFolder(fake_dir, label=0, transform=transform)\n\n# Combine and create DataLoader\ntrain_dataset = ConcatDataset([real_dataset, fake_dataset])\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\n# Equalized learning rate layers\nclass EqualizedLinear(nn.Module):\n    def __init__(self, in_features, out_features, gain=1.0):\n        super(EqualizedLinear, self).__init__()\n        \n        self.in_features = in_features\n        self.out_features = out_features\n        self.gain = gain\n        \n        # Initialize weights using equalized initialization\n        self.weight = nn.Parameter(torch.randn(out_features, in_features).div_(gain))\n        self.bias = nn.Parameter(torch.zeros(out_features))\n        \n    def forward(self, x):\n        # Apply the equalized weights to the input\n        return F.linear(x, self.weight, self.bias)\n\nclass EqualizedConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # Initialize weights with scaled variance\n        scale = 1 / np.sqrt(in_channels * kernel_size * kernel_size)\n        nn.init.normal_(conv.weight.data, 0.0, 1.0)\n        conv.weight.data.mul_(scale)\n        nn.init.zeros_(conv.bias.data)\n        self.conv = conv\n        self.scale = scale\n        \n    def forward(self, x):\n        return self.conv(x)\n\n# Fixed MinibatchStdDev implementation\nclass MinibatchStdDev(nn.Module):\n    def __init__(self, group_size=4):\n        super().__init__()\n        self.group_size = group_size\n        \n    def forward(self, x):\n        batch_size, channels, height, width = x.shape\n        \n        # If batch size is not divisible by group size, adjust group size\n        if batch_size % self.group_size != 0:\n            group_size = batch_size\n        else:\n            group_size = self.group_size\n            \n        # Ensure group size is not larger than batch size\n        group_size = min(group_size, batch_size)\n        \n        # If group_size is 1, we can't compute std dev across groups, so use a simpler approach\n        if group_size == 1:\n            # Add a single channel of zeros (simplest fallback)\n            zeros = torch.zeros(batch_size, 1, height, width, device=x.device)\n            return torch.cat([x, zeros], dim=1)\n            \n        # Handle group division\n        n_groups = batch_size // group_size\n        \n        # Reshape for group-wise calculation\n        y = x.view(group_size, n_groups, channels, height, width)\n        \n        # Calculate standard deviation for each group\n        y = torch.std(y, dim=0, unbiased=False)  # [n_groups, channels, height, width]\n        \n        # Average over all channels\n        y = y.mean(dim=1, keepdim=True)  # [n_groups, 1, height, width]\n        \n        # Expand to match input batch size\n        y = y.repeat(group_size, 1, 1, 1)  # [batch_size, 1, height, width]\n        \n        # If we don't have exactly batch_size elements, slice the tensor\n        if y.size(0) != batch_size:\n            y = y[:batch_size]\n            \n        # Concatenate along channel dimension\n        return torch.cat([x, y], dim=1)\n\n# Discriminator\nclass StyleGANDiscriminator(nn.Module):\n    def __init__(self, channels=32):\n        super().__init__()\n        self.from_rgb = EqualizedConv2d(3, channels, 1)\n        self.features = nn.ModuleList([\n            nn.Sequential(\n                EqualizedConv2d(channels, channels * 2, 4, 2, 1),\n                nn.LeakyReLU(0.2)\n            ),\n            nn.Sequential(\n                EqualizedConv2d(channels * 2, channels * 4, 4, 2, 1),\n                nn.LeakyReLU(0.2)\n            ),\n            nn.Sequential(\n                EqualizedConv2d(channels * 4, channels * 8, 4, 2, 1),\n                nn.LeakyReLU(0.2)\n            )\n        ])\n        self.final_block = nn.Sequential(\n            MinibatchStdDev(),\n            EqualizedConv2d(channels * 8 + 1, channels * 8, 3, 1, 1),\n            nn.LeakyReLU(0.2),\n            EqualizedConv2d(channels * 8, channels * 4, 4, 1, 0),\n            nn.LeakyReLU(0.2),\n            nn.Flatten(),\n            EqualizedLinear(channels * 4, 1)\n        )\n        \n    def forward(self, x):\n        x = self.from_rgb(x)\n        for block in self.features:\n            x = block(x)\n        validity = self.final_block(x)\n        return validity\n\n# Initialize Discriminator\ndiscriminator = StyleGANDiscriminator().to(device)\n\n# Load the pre-trained discriminator weights\npretrained_path = \"/kaggle/input/discriminatortdl/improved_stylegan_discriminator.pth\"\ntry:\n    discriminator.load_state_dict(torch.load(pretrained_path, map_location=device))\n    print(f\"Successfully loaded pre-trained discriminator from {pretrained_path}\")\nexcept Exception as e:\n    print(f\"Error loading pre-trained model: {e}\")\n    print(\"Continuing with randomly initialized weights...\")\n\n# Optimizer for discriminator - lower learning rate for fine-tuning\nd_optimizer = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, beta2))\n\n# Loss function\ndef discriminator_loss(real_validity, fake_validity):\n    real_loss = F.softplus(-real_validity).mean()\n    fake_loss = F.softplus(fake_validity).mean()\n    return real_loss + fake_loss\n\n# Function to fine-tune the discriminator\ndef finetune_discriminator():\n    D_losses = []\n    D_accuracies = []\n    print(\"Starting Fine-tuning Loop for Discriminator...\")\n    \n    for epoch in range(num_epochs):\n        total_d_loss = 0\n        num_batches = 0\n        correct_predictions = 0\n        total_samples = 0\n        \n        for batch_imgs, batch_labels in train_loader:\n            batch_size = batch_imgs.size(0)\n            \n            # Separate real and fake images based on labels\n            real_mask = (batch_labels == 1)\n            fake_mask = (batch_labels == 0)\n            \n            real_imgs = batch_imgs[real_mask].to(device)\n            fake_imgs = batch_imgs[fake_mask].to(device)\n            \n            # Skip this batch if either all real or all fake\n            if len(real_imgs) == 0 or len(fake_imgs) == 0:\n                continue\n                \n            # Make sure we have equal numbers of real and fake images\n            min_size = min(len(real_imgs), len(fake_imgs))\n            real_imgs = real_imgs[:min_size]\n            fake_imgs = fake_imgs[:min_size]\n            \n            # Combine for accuracy calculation\n            all_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n            all_labels = torch.cat([\n                torch.ones(min_size, device=device),\n                torch.zeros(min_size, device=device)\n            ])\n            \n            # Forward pass through discriminator\n            d_optimizer.zero_grad()\n            \n            real_validity = discriminator(real_imgs)\n            fake_validity = discriminator(fake_imgs)\n            \n            # Calculate accuracy\n            all_validity = discriminator(all_imgs)\n            predicted_labels = (all_validity > 0).float().view(-1)\n            correct = (predicted_labels == all_labels).sum().item()\n            correct_predictions += correct\n            total_samples += len(all_labels)\n            \n            # Compute loss for discriminator\n            d_loss = discriminator_loss(real_validity, fake_validity)\n            \n            # Backpropagation and optimization\n            d_loss.backward()\n            d_optimizer.step()\n            \n            total_d_loss += d_loss.item()\n            num_batches += 1\n            \n            # Save loss for plotting\n            D_losses.append(d_loss.item())\n            \n            # Print progress\n            if num_batches % 50 == 0:\n                print(f\"[Epoch {epoch+1}/{num_epochs}] [Batch {num_batches}/{len(train_loader)}] \"\n                      f\"[D loss: {d_loss.item():.4f}]\")\n        \n        # Calculate accuracy for this epoch\n        epoch_accuracy = correct_predictions / total_samples if total_samples > 0 else 0\n        D_accuracies.append(epoch_accuracy)\n        \n        # Print epoch summary\n        avg_loss = total_d_loss / num_batches if num_batches > 0 else 0\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {avg_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n    \n    return D_losses, D_accuracies\n\n# Run fine-tuning for the discriminator\nD_losses, D_accuracies = finetune_discriminator()\n\n# Plot discriminator loss and accuracy\nplt.figure(figsize=(12, 5))\n\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(D_losses)\nplt.title(\"Discriminator Fine-tuning Loss\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.grid(True)\n\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs + 1), D_accuracies, marker='o')\nplt.title(\"Discriminator Accuracy per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\n\n# Save the plot to a file\nplt.tight_layout()\nplt.savefig(\"discriminator_finetuning_stylegan_cifake.png\")\n\n# Display the plot\nplt.show()\n\n# Save the fine-tuned discriminator model\ntorch.save(discriminator.state_dict(), \"finetuned_stylegan_discriminator_cifake.pth\")\n\n# Evaluate on test set if available\ntry:\n    test_real_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL\"\n    test_fake_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE\"\n    \n    test_real_dataset = FlatImageFolder(test_real_dir, label=1, transform=transform)\n    test_fake_dataset = FlatImageFolder(test_fake_dir, label=0, transform=transform)\n    test_dataset = ConcatDataset([test_real_dataset, test_fake_dataset])\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    \n    discriminator.eval()\n    test_correct = 0\n    test_total = 0\n    \n    with torch.no_grad():\n        for batch_imgs, batch_labels in test_loader:\n            batch_imgs = batch_imgs.to(device)\n            batch_labels = batch_labels.float().to(device)\n            \n            outputs = discriminator(batch_imgs)\n            predicted = (outputs > 0).float().view(-1)\n            test_correct += (predicted == batch_labels).sum().item()\n            test_total += batch_labels.size(0)\n    \n    test_accuracy = test_correct / test_total\n    print(f\"Test accuracy: {test_accuracy:.4f}\")\n    \nexcept Exception as e:\n    print(f\"Test set evaluation failed: {e}\")\n    print(\"Skipping test set evaluation.\")\n\nprint(\"Fine-tuning complete! Discriminator saved to 'finetuned_stylegan_discriminator_cifake.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T06:55:52.001452Z","iopub.execute_input":"2025-04-20T06:55:52.002024Z","iopub.status.idle":"2025-04-20T07:09:29.129843Z","shell.execute_reply.started":"2025-04-20T06:55:52.001991Z","shell.execute_reply":"2025-04-20T07:09:29.129049Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nfrom torchvision.utils import save_image, make_grid\nimport os\nfrom PIL import Image\n\n# Set random seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\n# Parameters\nbatch_size = 64\nimg_channels = 3\nimage_size = 32\nnum_epochs = 10\nlr = 0.0002\nbeta1 = 0.5\nbeta2 = 0.999\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n])\n\n# Custom Dataset for loading flat directory of images with a specific label\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.label = label\n        self.image_files = [os.path.join(root_dir, f) for f in os.listdir(root_dir)\n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = self.image_files[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, self.label\n\n# Dataset paths\nreal_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL\"\nfake_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE\"\n\n# Datasets\nreal_dataset = FlatImageFolder(real_dir, label=1, transform=transform)\nfake_dataset = FlatImageFolder(fake_dir, label=0, transform=transform)\n\n# Combine and create DataLoader\ntrain_dataset = ConcatDataset([real_dataset, fake_dataset])\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\n# Define the Discriminator model from IC-GAN\nclass Discriminator(nn.Module):\n    def __init__(self, img_channels=3):\n        super().__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(img_channels, 32, 3, 2, 1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(32, 64, 3, 2, 1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(64, 128, 3, 2, 1),  # 8x8 -> 4x4\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n\n        self.final = nn.Conv2d(128, 256, 4, 1, 0)  # 4x4 -> 1x1\n        self.output = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, img):\n        features = self.features(img)\n        final_features = self.final(features)\n        validity = self.output(final_features)\n        return validity, final_features\n\n# Discriminator Training Class with Pretrained Weights\nclass DiscriminatorTrainer:\n    def __init__(self):\n        self.discriminator = Discriminator(img_channels).to(device)\n\n        # Load pretrained weights from IC-GAN\n        pretrained_path = \"/kaggle/input/discriminatortdl/icgan_discriminator.pth\"\n        state_dict = torch.load(pretrained_path, map_location=device)\n        self.discriminator.load_state_dict(state_dict, strict=False)\n        print(f\"âœ… Loaded pretrained weights from {pretrained_path}\")\n\n        self.optimizer = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n        self.criterion = nn.BCELoss()\n        self.model_name = \"CIFAKE-Discriminator-Finetune\"\n        self.losses = []\n        self.accuracies = []\n\n    def train(self, dataloader, num_epochs):\n        print(f\"ðŸš€ Starting {self.model_name} Fine-tuning...\")\n\n        for epoch in range(num_epochs):\n            epoch_loss = 0\n            correct = 0\n            total = 0\n\n            for i, (images, labels) in enumerate(dataloader):\n                images = images.to(device)\n                labels = labels.float().to(device).view(-1, 1)\n\n                self.optimizer.zero_grad()\n                predictions, _ = self.discriminator(images)\n                loss = self.criterion(predictions, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                epoch_loss += loss.item()\n                predicted = (predictions >= 0.5).float()\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n                if i % 50 == 0:\n                    print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] \"\n                          f\"[D loss: {loss.item():.4f}]\")\n\n            epoch_accuracy = 100 * correct / total\n            self.losses.append(epoch_loss / len(dataloader))\n            self.accuracies.append(epoch_accuracy)\n            print(f\"ðŸ“ˆ Epoch {epoch} - Loss: {epoch_loss/len(dataloader):.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n\n        torch.save(self.discriminator.state_dict(), \"cifake_discriminator_icgan_finetuned.pth\")\n        return self.losses, self.accuracies\n\n    def evaluate(self, dataloader):\n        self.discriminator.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in dataloader:\n                images = images.to(device)\n                labels = labels.float().to(device).view(-1, 1)\n                predictions, _ = self.discriminator(images)\n                predicted = (predictions >= 0.5).float()\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n        accuracy = 100 * correct / total\n        print(f\"âœ… Evaluation accuracy: {accuracy:.2f}%\")\n        return accuracy\n\n    def plot_metrics(self):\n        plt.figure(figsize=(12, 5))\n\n        plt.subplot(1, 2, 1)\n        plt.plot(self.losses)\n        plt.title(\"Discriminator Loss During Fine-tuning\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Loss\")\n\n        plt.subplot(1, 2, 2)\n        plt.plot(self.accuracies)\n        plt.title(\"Discriminator Accuracy During Fine-tuning\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Accuracy (%)\")\n\n        plt.tight_layout()\n        plt.savefig(\"finetune_metrics_icgan.png\")\n        plt.show()\n\n    def visualize_samples(self, dataloader, num_samples=8):\n        self.discriminator.eval()\n        images, labels = next(iter(dataloader))\n        images = images[:num_samples].to(device)\n        labels = labels[:num_samples].float().to(device).view(-1, 1)\n\n        with torch.no_grad():\n            predictions, _ = self.discriminator(images)\n            predicted_labels = (predictions >= 0.5).float()\n            images = (images.cpu() + 1) / 2  # Denormalize\n\n            fig, axes = plt.subplots(1, num_samples, figsize=(16, 4))\n            for i in range(num_samples):\n                axes[i].imshow(images[i].permute(1, 2, 0))\n                real_label = \"Real\" if labels[i].item() == 1 else \"Fake\"\n                pred_label = \"Real\" if predicted_labels[i].item() == 1 else \"Fake\"\n                color = \"green\" if labels[i].item() == predicted_labels[i].item() else \"red\"\n                axes[i].set_title(f\"True: {real_label}\\nPred: {pred_label}\", color=color)\n                axes[i].axis('off')\n\n            plt.tight_layout()\n            plt.savefig(\"sample_predictions_finetune_icgan.png\")\n            plt.show()\n\n# Run everything\ntrainer = DiscriminatorTrainer()\nlosses, accuracies = trainer.train(train_loader, num_epochs)\ntrainer.plot_metrics()\ntrainer.visualize_samples(train_loader)\nprint(\"âœ… CIFAKE Discriminator fine-tuning complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T07:12:34.878786Z","iopub.execute_input":"2025-04-20T07:12:34.879313Z","iopub.status.idle":"2025-04-20T07:22:42.424871Z","shell.execute_reply.started":"2025-04-20T07:12:34.879287Z","shell.execute_reply":"2025-04-20T07:22:42.423960Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVALUATION","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nfrom torchvision.utils import save_image, make_grid\nimport os\nfrom PIL import Image\n\n# 1. Define your Discriminator class (already done by you)\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.main(x).view(-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:35:55.377263Z","iopub.execute_input":"2025-04-21T15:35:55.377494Z","iopub.status.idle":"2025-04-21T15:36:02.008572Z","shell.execute_reply.started":"2025-04-21T15:35:55.377475Z","shell.execute_reply":"2025-04-21T15:36:02.008017Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\nbatch_size = 64\nimage_size = 32\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.root_dir = root_dir\n        self.image_paths = [\n            os.path.join(root_dir, fname)\n            for fname in os.listdir(root_dir)\n            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n        ]\n        self.transform = transform\n        self.label = label\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.label\n\n# Image transforms\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:37:44.628289Z","iopub.execute_input":"2025-04-21T15:37:44.628861Z","iopub.status.idle":"2025-04-21T15:37:44.688319Z","shell.execute_reply.started":"2025-04-21T15:37:44.628835Z","shell.execute_reply":"2025-04-21T15:37:44.687360Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# STYLEGAN","metadata":{}},{"cell_type":"code","source":"# â”€â”€ 1) Imports & Seed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image\nfrom torchvision import transforms\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n\n# reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# â”€â”€ 2) Custom Layers (with FIXED MinibatchStdDev) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass EqualizedLinear(nn.Module):\n    def __init__(self, in_f, out_f, gain=1.0):\n        super().__init__()\n        self.weight = nn.Parameter(torch.randn(out_f, in_f).div_(gain))\n        self.bias   = nn.Parameter(torch.zeros(out_f))\n    def forward(self, x):\n        return F.linear(x, self.weight, self.bias)\n\nclass EqualizedConv2d(nn.Module):\n    def __init__(self, in_ch, out_ch, k, stride=1, pad=0):\n        super().__init__()\n        conv = nn.Conv2d(in_ch, out_ch, k, stride, pad)\n        scale = 1/np.sqrt(in_ch * k * k)\n        nn.init.normal_(conv.weight, 0.0, 1.0)\n        conv.weight.data.mul_(scale)\n        nn.init.zeros_(conv.bias)\n        self.conv = conv\n    def forward(self, x):\n        return self.conv(x)\n\nclass MinibatchStdDev(nn.Module):\n    def __init__(self, group_size=4):\n        super().__init__()\n        self.group_size = group_size\n\n    def forward(self, x):\n        bs, ch, h, w = x.shape\n        # pick group_size <= bs\n        g = min(self.group_size, bs)\n        if g <= 1:\n            zeros = torch.zeros(bs, 1, h, w, device=x.device)\n            return torch.cat([x, zeros], dim=1)\n\n        # reshape into (g, n_groups, ch, h, w)\n        n = bs // g\n        y = x.view(g, n, ch, h, w)\n        y = y.std(dim=0, unbiased=False)        # â†’ (n, ch, h, w)\n        y = y.mean(dim=1, keepdim=True)         # â†’ (n, 1, h, w)\n        # expand only along the batch axis, keep h,w intact\n        y = y.repeat(g, 1, 1, 1)                # â†’ (n*g=bs, 1, h, w)\n        y = y[:bs]                              # just in case\n        return torch.cat([x, y], dim=1)         # â†’ (bs, ch+1, h, w)\n\n\n# â”€â”€ 3) StyleGAN Discriminator Definition â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass StyleGANDiscriminator(nn.Module):\n    def __init__(self, channels=32):\n        super().__init__()\n        self.from_rgb = EqualizedConv2d(3, channels, 1)\n        self.features = nn.ModuleList([\n            nn.Sequential(EqualizedConv2d(channels,   channels*2, 4, 2, 1),\n                          nn.LeakyReLU(0.2)),\n            nn.Sequential(EqualizedConv2d(channels*2, channels*4, 4, 2, 1),\n                          nn.LeakyReLU(0.2)),\n            nn.Sequential(EqualizedConv2d(channels*4, channels*8, 4, 2, 1),\n                          nn.LeakyReLU(0.2)),\n        ])\n        self.final_block = nn.Sequential(\n            MinibatchStdDev(),\n            EqualizedConv2d(channels*8 + 1, channels*8, 3, 1, 1),\n            nn.LeakyReLU(0.2),\n            EqualizedConv2d(channels*8, channels*4, 4, 1, 0),\n            nn.LeakyReLU(0.2),\n            nn.Flatten(),\n            EqualizedLinear(channels*4, 1)\n        )\n\n    def forward(self, x):\n        x = self.from_rgb(x)\n        for block in self.features:\n            x = block(x)\n        return self.final_block(x).view(-1)   # â†’ (batch_size,)\n\n\n# â”€â”€ 4) Build Test DataLoader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.paths = sorted(\n            os.path.join(root_dir, f)\n            for f in os.listdir(root_dir)\n            if f.lower().endswith(('.png','.jpg','jpeg'))\n        )\n        self.transform = transform\n        self.label = label\n\n    def __len__(self): return len(self.paths)\n    def __getitem__(self, i):\n        img = Image.open(self.paths[i]).convert('RGB')\n        if self.transform: img = self.transform(img)\n        return img, self.label\n\nimage_size = 32\nbatch_size = 64\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n])\n\nreal_test = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL\"\nfake_test = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE\"\n\nreal_ds = FlatImageFolder(real_test, 1, transform)\nfake_ds = FlatImageFolder(fake_test, 0, transform)\ntest_loader = DataLoader(\n    ConcatDataset([real_ds, fake_ds]),\n    batch_size=batch_size, shuffle=False, num_workers=2\n)\n\n\n# â”€â”€ 5) Instantiate & Load with Key Remapping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmodel = StyleGANDiscriminator().to(device)\nckpt = \"/kaggle/input/finetunedgans/finetuned_stylegan_discriminator_cifake.pth\"\nraw_state = torch.load(ckpt, map_location=device)\n\nfixed_state = {}\nfor k,v in raw_state.items():\n    if k.startswith(\"final_block.6.linear\"):\n        fixed_state[k.replace(\"final_block.6.linear\", \"final_block.6\")] = v\n    else:\n        fixed_state[k] = v\n\n# load and report any leftover mismatches\nmiss, unexp = model.load_state_dict(fixed_state, strict=False)\nprint(\"Missing keys:\", miss)\nprint(\"Unexpected keys:\", unexp)\nmodel.eval()\n\n\n# â”€â”€ 6) Evaluation Function & Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef evaluate_discriminator(model, loader, name=\"Discriminator\"):\n    all_p, all_preds, all_labels = [], [], []\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs = imgs.to(device)\n            logits = model(imgs)          # already linear outputs\n            probs  = torch.sigmoid(logits)\n            preds  = (probs >= 0.5).long()\n\n            all_p.extend(probs.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    cm  = confusion_matrix(all_labels, all_preds)\n    cr  = classification_report(all_labels, all_preds, target_names=[\"Fake\",\"Real\"])\n    auc = roc_auc_score(all_labels, all_p)\n\n    print(f\"\\nðŸ§ª Evaluation for {name}\")\n    print(f\"âœ… Accuracy: {acc * 100:.2f}%\")\n    print(f\"ðŸ“Š Confusion Matrix:\\n{cm}\")\n    print(f\"ðŸ“‹ Classification Report:\\n{cr}\")\n    print(f\"ðŸ“ˆ ROC-AUC Score: {auc:.4f}\")\n\n# finally, run it:\nevaluate_discriminator(model, test_loader, name=\"StyleGAN Discriminator\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T16:01:02.292077Z","iopub.execute_input":"2025-04-21T16:01:02.292763Z","iopub.status.idle":"2025-04-21T16:01:25.238268Z","shell.execute_reply.started":"2025-04-21T16:01:02.292735Z","shell.execute_reply":"2025-04-21T16:01:25.237262Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/488887005.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  raw_state = torch.load(ckpt, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Missing keys: []\nUnexpected keys: []\n\nðŸ§ª Evaluation for StyleGAN Discriminator\nâœ… Accuracy: 96.89%\nðŸ“Š Confusion Matrix:\n[[9531  469]\n [ 153 9847]]\nðŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\n        Fake       0.98      0.95      0.97     10000\n        Real       0.95      0.98      0.97     10000\n\n    accuracy                           0.97     20000\n   macro avg       0.97      0.97      0.97     20000\nweighted avg       0.97      0.97      0.97     20000\n\nðŸ“ˆ ROC-AUC Score: 0.9959\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# DCGAN\n","metadata":{}},{"cell_type":"code","source":"# Notebook: Load and Evaluate Fine-tuned DCGAN Discriminator\n\n# â”€â”€ 1) Imports & Seed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision import transforms\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n\n# Reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# â”€â”€ 2) Dataset Class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.paths = sorted(\n            os.path.join(root_dir, f)\n            for f in os.listdir(root_dir)\n            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n        )\n        self.transform = transform\n        self.label = label\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.label\n\n# â”€â”€ 3) Transforms & Test DataLoader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimage_size = 32\nbatch_size = 128\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),  # normalize RGB\n])\n\nreal_test_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL\"\nfake_test_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE\"\n\nreal_test_ds = FlatImageFolder(real_test_dir, label=1, transform=transform)\nfake_test_ds = FlatImageFolder(fake_test_dir, label=0, transform=transform)\n\ntest_loader = DataLoader(\n    ConcatDataset([real_test_ds, fake_test_ds]),\n    batch_size=batch_size, shuffle=False, num_workers=2\n)\n\n# â”€â”€ 4) Discriminator Definition â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nnc, ndf = 3, 64  # channels, feature maps\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf*2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf*4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf*4, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.main(x).view(-1)\n\n# â”€â”€ 5) Instantiate & Load Fine-tuned Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmodel = Discriminator().to(device)\nckpt_path = \"/kaggle/input/finetunedgans/finetuned_discriminator_cifake.pth\"  # adjust path if needed\nstate = torch.load(ckpt_path, map_location=device)\nmodel.load_state_dict(state)\nmodel.eval()\nprint(f\"Loaded fine-tuned discriminator from {ckpt_path}\")\n\n# â”€â”€ 6) Evaluation Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef evaluate_discriminator(model, loader, name=\"Discriminator\"):\n    model.eval()\n    all_probs, all_preds, all_labels = [], [], []\n\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs = imgs.to(device)\n            # Forward pass\n            outputs = model(imgs)  # already sigmoid-activated\n            probs = outputs.cpu().numpy()\n            preds = (probs >= 0.5).astype(int)\n\n            all_probs.extend(probs)\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    # Metrics\n    acc = accuracy_score(all_labels, all_preds)\n    cm  = confusion_matrix(all_labels, all_preds)\n    cr  = classification_report(all_labels, all_preds, target_names=[\"Fake\",\"Real\"])\n    auc = roc_auc_score(all_labels, all_probs)\n\n    # Print results\n    print(f\"\\nðŸ§ª Evaluation for {name}\")\n    print(f\"âœ… Accuracy: {acc * 100:.2f}%\")\n    print(f\"ðŸ“Š Confusion Matrix:\\n{cm}\")\n    print(f\"ðŸ“‹ Classification Report:\\n{cr}\")\n    print(f\"ðŸ“ˆ ROC-AUC Score: {auc:.4f}\")\n\n# â”€â”€ 7) Run Evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nevaluate_discriminator(model, test_loader, name=\"DCGAN Discriminator\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T16:03:58.565427Z","iopub.execute_input":"2025-04-21T16:03:58.566167Z","iopub.status.idle":"2025-04-21T16:04:16.272906Z","shell.execute_reply.started":"2025-04-21T16:03:58.566136Z","shell.execute_reply":"2025-04-21T16:04:16.272007Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoaded fine-tuned discriminator from /kaggle/input/finetunedgans/finetuned_discriminator_cifake.pth\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1969671936.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ§ª Evaluation for DCGAN Discriminator\nâœ… Accuracy: 94.71%\nðŸ“Š Confusion Matrix:\n[[9533  467]\n [ 591 9409]]\nðŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\n        Fake       0.94      0.95      0.95     10000\n        Real       0.95      0.94      0.95     10000\n\n    accuracy                           0.95     20000\n   macro avg       0.95      0.95      0.95     20000\nweighted avg       0.95      0.95      0.95     20000\n\nðŸ“ˆ ROC-AUC Score: 0.9883\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# ICGAN","metadata":{}},{"cell_type":"code","source":"# Notebook: Load and Evaluate Fine-tuned IC-GAN Discriminator\n\n# â”€â”€ 1) Imports & Seed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision import transforms\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n\n# Reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# â”€â”€ 2) Dataset & Transforms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass FlatImageFolder(Dataset):\n    def __init__(self, root_dir, label, transform=None):\n        self.image_paths = sorted(\n            os.path.join(root_dir, f)\n            for f in os.listdir(root_dir)\n            if f.lower().endswith(('.png','.jpg','.jpeg'))\n        )\n        self.transform = transform\n        self.label = label\n\n    def __len__(self): return len(self.image_paths)\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, self.label\n\n# Parameters\nbatch_size  = 64\nimage_size  = 32\nimg_channels = 3\n\n# Transforms\ntf = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n])\n\n# Test directories (adjust paths as needed)\nreal_test_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL\"\nfake_test_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE\"\n\nreal_ds = FlatImageFolder(real_test_dir, 1, tf)\nfake_ds = FlatImageFolder(fake_test_dir, 0, tf)\n\ntest_loader = DataLoader(\n    ConcatDataset([real_ds, fake_ds]),\n    batch_size=batch_size, shuffle=False, num_workers=2\n)\n\n# â”€â”€ 3) Model Definition â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass Discriminator(nn.Module):\n    def __init__(self, img_channels=3):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(img_channels, 32, 3, 2, 1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(32, 64, 3, 2, 1),             # 16x16 -> 8x8\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 3, 2, 1),            # 8x8 -> 4x4\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.final = nn.Conv2d(128, 256, 4, 1, 0)   # 4x4 -> 1x1\n        self.output = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x_feat = self.features(x)\n        x_fin  = self.final(x_feat)\n        validity = self.output(x_fin)\n        return validity.view(-1)\n\n# â”€â”€ 4) Instantiate & Load Checkpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmodel = Discriminator(img_channels).to(device)\nckpt_path = \"/kaggle/input/finetunedgans/cifake_discriminator_icgan_finetuned.pth\"  # adjust if needed\nstate = torch.load(ckpt_path, map_location=device)\nmodel.load_state_dict(state)\nmodel.eval()\nprint(f\"Loaded fine-tuned IC-GAN Discriminator from {ckpt_path}\")\n\n# â”€â”€ 5) Evaluation Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef evaluate_discriminator(model, loader, name=\"Discriminator\"):\n    all_probs, all_preds, all_labels = [], [], []\n    model.eval()\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs = imgs.to(device)\n            probs = model(imgs).cpu().numpy()       # outputs in [0,1]\n            preds = (probs >= 0.5).astype(int)\n            all_probs.extend(probs)\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    cm  = confusion_matrix(all_labels, all_preds)\n    cr  = classification_report(all_labels, all_preds, target_names=[\"Fake\",\"Real\"])\n    auc = roc_auc_score(all_labels, all_probs)\n\n    print(f\"\\nðŸ§ª Evaluation for {name}\")\n    print(f\"âœ… Accuracy: {acc * 100:.2f}%\")\n    print(f\"ðŸ“Š Confusion Matrix:\\n{cm}\")\n    print(f\"ðŸ“‹ Classification Report:\\n{cr}\")\n    print(f\"ðŸ“ˆ ROC-AUC Score: {auc:.4f}\")\n\n# â”€â”€ 6) Run Evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nevaluate_discriminator(model, test_loader, name=\"IC-GAN Discriminator\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T16:13:12.464135Z","iopub.execute_input":"2025-04-21T16:13:12.464404Z","iopub.status.idle":"2025-04-21T16:13:34.244919Z","shell.execute_reply.started":"2025-04-21T16:13:12.464386Z","shell.execute_reply":"2025-04-21T16:13:34.244154Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoaded fine-tuned IC-GAN Discriminator from /kaggle/input/finetunedgans/cifake_discriminator_icgan_finetuned.pth\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/2317630900.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ§ª Evaluation for IC-GAN Discriminator\nâœ… Accuracy: 94.19%\nðŸ“Š Confusion Matrix:\n[[9419  581]\n [ 582 9418]]\nðŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\n        Fake       0.94      0.94      0.94     10000\n        Real       0.94      0.94      0.94     10000\n\n    accuracy                           0.94     20000\n   macro avg       0.94      0.94      0.94     20000\nweighted avg       0.94      0.94      0.94     20000\n\nðŸ“ˆ ROC-AUC Score: 0.9858\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}